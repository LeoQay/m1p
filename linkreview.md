# Обзор литературы

| Название | Авторы   | Ссылка   | Основные идеи   |
|----------|----------|----------|----------|
| New Two-Level Ensemble Method and Its Application to Chemical Compounds Properties Prediction    | O.V. Senko, A.A. Dokukin, N.N. Kiselyova, V.A. Dudarev, Yu.O. Kuznetsova   | [Ссылка](https://damdid2022.frccsc.ru/files/article/DAMDID_2022_paper_1620.pdf) | В статье рассматривается новый метод двухуровневой ансамблевой регрессии и его применение к задачам прогнозирования. На первом этапе прогнозирование целевой переменной выполняется с помощью деревьев регрессии, включенных в оптимальный ансамбль нижнего уровня. Агрегированное решение вычисляется с помощью регрессионного случайного леса, используя предсказания, вычисленные с помощью деревьев ансамбля в качестве объектов. Отличительной особенностью метода является новый метод получения деревьев, добавленных в ансамбль, который основан на минимизации специального функционала, представляющего собой разницу двух компонентов. Первый компонент характеризует точность аппроксимации взаимосвязи между целевой переменной и входными признаками и равен стандартному отклонению прогнозов от значений целевой переменной. Второй компонент направлен на увеличение дисперсии прогнозов с помощью ансамблевых алгоритмов. При построении оптимального ансамбля используется комбинация подходов, используемых в методе случайного леса, и градиентного бустинга. |
| Liu, Y., Wang, Y., Zhang, J. | New Machine Learning Algorithm: Random Forest. | [Ссылка](https://link.springer.com/chapter/10.1007/978-3-642-34062-8_32) | Традиционные алгоритмы машинного обучения обычно дают низкую точность классификатора и легко поддаются переобучению. Чтобы повысить точность, многие ученые начинают исследования по повышению точности классификации с помощью объединения классификаторов. В 1996 году Лео Брейман усовершенствовал алгоритм упаковки в пакеты, который является одним из алгоритмов ранней стадии. Амит и Геман определяют большое количество геометрических объектов и выполняют поиск по их случайной выборке для наилучшего разделения на каждой вершине. В 1998 году Диттерих выдвинул теорию случайного раздельного отбора. В каждом узле разбиение выбирается случайным образом из N лучших разбиений. Хо провел много исследований по методу “случайного подпространства”, который выращивает каждое дерево путем случайного выбора подмножества объектов. Брейман генерирует новые обучающие наборы путем рандомизации выходных данных в исходном обучающем наборе. Среди них идея, изложенная в статье Амита и Гемана, повлияла на размышления Бреймана о случайных лесах. |

